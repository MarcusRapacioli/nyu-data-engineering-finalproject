{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3472aa",
   "metadata": {},
   "source": [
    "Final project. Built on all five homeworks and Max's code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92186c7",
   "metadata": {},
   "source": [
    "Process:\n",
    "\n",
    "The goal of this project was to improve upon the existing work. I sought to do this in three ways:\n",
    "1. Establish a MongoDB database as a nosql is faster than an sql solution\n",
    "2. Use more training data on currency pairs in the prediction model. In theory, more data should yield more accurate results\n",
    "3. Add data points on US treasuries to the model. US treasury prices are highly sensitive to inflation. In theory treasuries should offer a sort of proxy for inflation, which is in turn a key determinant of forex prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c187ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import datetime\n",
    "import time\n",
    "from polygon import RESTClient\n",
    "from sqlalchemy import create_engine \n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from math import isnan\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547d13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary defining the set of currency pairs we will be pulling data for\n",
    "currency_pairs = [[\"EUR\",\"USD\",],\n",
    "                  [\"GBP\",\"USD\",],\n",
    "                  [\"USD\",\"CHF\",],\n",
    "                  [\"USD\",\"CAD\",],\n",
    "                  [\"USD\",\"HKD\",],\n",
    "                  [\"USD\",\"AUD\",],\n",
    "                  [\"USD\",\"NZD\",],\n",
    "                  [\"USD\",\"SGD\",]]\n",
    "\n",
    "\n",
    "# Do the necessary imports\n",
    "\n",
    "import pandas as pd\n",
    "from pycaret.regression import *\n",
    "\n",
    "#Create dictionaries to house our raw data and prepared data \n",
    "\n",
    "data = {} # raw compiled data\n",
    "data1 = {} # from first data collection\n",
    "data2 = {} # from second data collection\n",
    "data3 = {} # from third data collection\n",
    "prepared = {}\n",
    "\n",
    "# Create dictionaries that hold volatility and fd data, we will use these in the main function to assign a class to vol and fd\n",
    "vol_data = {}\n",
    "fd_data = {}\n",
    "\n",
    "# Import the treasury data that we will add to the model\n",
    "treasury_data = pd.read_csv(f'treasury_data/treasury_data.csv')\n",
    "\n",
    "# Set the index of the treasury data to the date column so that we can select the value\n",
    "td = treasury_data.set_index('date')\n",
    "\n",
    "\n",
    "# Import our training data from the training_data directories\n",
    "for currency in currency_pairs:\n",
    "        # Set the input variables to the API\n",
    "        from_ = currency[0]\n",
    "        to = currency[1]\n",
    "        data1[f'{from_}{to}'] = pd.read_csv(f'training_data1/{from_}{to}_ts.csv')\n",
    "        data2[f'{from_}{to}'] = pd.read_csv(f'training_data2/{from_}{to}_ts.csv')\n",
    "        data3[f'{from_}{to}'] = pd.read_csv(f'training_data3/{from_}{to}_ts.csv')\n",
    "\n",
    "        \n",
    "        data[f'{from_}{to}'] = data1[f'{from_}{to}'].append(data2[f'{from_}{to}'], ignore_index=True).append(data3[f'{from_}{to}'], ignore_index=True)\n",
    "                \n",
    "        \n",
    "        dates = ['11/29', '11/30', '12/4', '12/5', '12/14', '12/15']\n",
    "        \n",
    "        \n",
    "        for date in dates:\n",
    "            \n",
    "            # Add the five year treasury yields to the dataset\n",
    "            data[f'{from_}{to}'].loc[data[f'{from_}{to}']['inserttime'].str.contains(date), 'fiveyear' ] = td.loc[date, 'fiveyear']\n",
    "\n",
    "            # Add the ten year treasury yields to the dataset\n",
    "            data[f'{from_}{to}'].loc[data[f'{from_}{to}']['inserttime'].str.contains(date), 'tenyear' ] = td.loc[date, 'tenyear']\n",
    "\n",
    "            # Add the ten year treasury yields to the dataset\n",
    "            data[f'{from_}{to}'].loc[data[f'{from_}{to}']['inserttime'].str.contains(date), 'thirtyyear' ] = td.loc[date, 'thirtyyear']\n",
    "\n",
    "        \n",
    "        \n",
    "        # Remove the time period coloumn as it will skew the prediction\n",
    "        del data[f'{from_}{to}']['period']\n",
    "        \n",
    "        \n",
    "        # Sort the values by volatility \n",
    "        data[f'{from_}{to}'] = data[f'{from_}{to}'].sort_values(by = [\"volatility\"])\n",
    "        data[f'{from_}{to}'].reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        \n",
    "        # Save the vol data to classify real time data points, we need to use the copy() method or else our array will be replaced by the classifications\n",
    "        vol_data[f'{from_}{to}'] = data[f'{from_}{to}'].loc[0:, 'volatility'].copy()\n",
    "     \n",
    "        \n",
    "        # Assign the volatility values into high, medium and low classifications\n",
    "        data[f'{from_}{to}'].loc[0:120, 'volatility'] = 1\n",
    "        data[f'{from_}{to}'].loc[121:240, 'volatility'] = 2\n",
    "        data[f'{from_}{to}'].loc[241:, 'volatility'] = 3\n",
    "        \n",
    "        \n",
    "        # Repeat the process for fractal dimension\n",
    "        data[f'{from_}{to}'] = data[f'{from_}{to}'].sort_values(by = [\"fd\"])\n",
    "        data[f'{from_}{to}'].reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        \n",
    "        # Save the fd data to classify real time data points, we need to use the copy() method or else our array will be replaced by the classifications\n",
    "        fd_data[f'{from_}{to}'] = data[f'{from_}{to}'].loc[0:, 'fd'].copy()\n",
    "        \n",
    "\n",
    "        # Assign the fd values into high, medium and low classifications\n",
    "        data[f'{from_}{to}'].loc[0:120, 'fd'] = 1\n",
    "        data[f'{from_}{to}'].loc[121:240, 'fd'] = 2\n",
    "        data[f'{from_}{to}'].loc[241:, 'fd'] = 3\n",
    "        \n",
    "        \n",
    "        # Multiply the return by 100000, this will make it easier to make predictions as otherwise our return values are all very closed to 0.\n",
    "        # We will divide the retuun by 100000 later\n",
    "        data[f'{from_}{to}'].loc[0:, 'return'] = data[f'{from_}{to}'].loc[0:, 'return'] *100000\n",
    "       \n",
    "    \n",
    "        # Add the prepared data for each currency to the prepared dictionary\n",
    "        prepared[f'{from_}{to}'] = data[f'{from_}{to}']\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of looping over the currency pairs as I do elsewhere in this project, I run each currency pair in a separate notebook block.\n",
    "# This was in order to select the best regression model that varied depending on the currency pair.\n",
    "\n",
    "# EURUSD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "EURUSD_reg = setup(data = prepared['EURUSD'], target = 'return', session_id=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9935876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "EURUSD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac311fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "EURUSD_lasso = create_model(\"lasso\")\n",
    "\n",
    "# Tune the model\n",
    "EURUSD_tuned_lasso = tune_model(EURUSD_lasso)\n",
    "\n",
    "# Finalise the model\n",
    "EURUSD_model = finalize_model(EURUSD_tuned_lasso)\n",
    "\n",
    "# Save the model (v important!)\n",
    "save_model(EURUSD_model, 'EURUSD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169717b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBPUSD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "GBPUSD_reg = setup(data = prepared['GBPUSD'], target = 'return', session_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e450e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "GBPUSD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bceaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "GBPUSD_lasso = create_model(\"lasso\")\n",
    "\n",
    "# Tune the model\n",
    "GBPUSD_tuned_lasso = tune_model(GBPUSD_lasso)\n",
    "\n",
    "# Finalise the model\n",
    "GBPUSD_model = finalize_model(GBPUSD_tuned_lasso)\n",
    "\n",
    "# Save the model\n",
    "save_model(GBPUSD_model, 'GBPUSD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77806c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDCHF\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDCHF_reg = setup(data = prepared['USDCHF'], target = 'return', session_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb064706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "USDCHF_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0735bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDCHF_llar = create_model(\"llar\")\n",
    "\n",
    "# Tune the model\n",
    "USDCHF_tuned_llar = tune_model(USDCHF_llar)\n",
    "\n",
    "# Finalise the model\n",
    "USDCHF_model = finalize_model(USDCHF_tuned_llar)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDCHF_model, 'USDCHF_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07196ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDCAD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDCAD_reg = setup(data = prepared['USDCAD'], target = 'return', session_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "USDCAD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac4d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDCAD_lasso = create_model(\"lasso\")\n",
    "\n",
    "# Tune the model\n",
    "USDCAD_tuned_lasso = tune_model(USDCAD_lasso)\n",
    "\n",
    "# Finalise the model\n",
    "USDCAD_model = finalize_model(USDCAD_tuned_lasso)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDCAD_model, 'USDCAD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d943455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDHKD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDHKD_reg = setup(data = prepared['USDHKD'], target = 'return', session_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "USDHKD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dda158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDHKD_llar = create_model(\"llar\")\n",
    "\n",
    "# Tune the model\n",
    "USDHKD_tuned_llar = tune_model(USDHKD_llar)\n",
    "\n",
    "# Finalise the model\n",
    "USDHKD_model = finalize_model(USDHKD_tuned_llar)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDHKD_model, 'USDHKD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDAUD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDAUD_reg = setup(data = prepared['USDAUD'], target = 'return', session_id=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fdd5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "USDAUD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd992f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDAUD_br = create_model(\"br\")\n",
    "\n",
    "# Tune the model\n",
    "USDAUD_tuned_br = tune_model(USDAUD_br)\n",
    "\n",
    "# Finalise the model\n",
    "USDAUD_model = finalize_model(USDAUD_tuned_br)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDAUD_model, 'USDAUD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDNZD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDNZD_reg = setup(data = prepared['USDNZD'], target = 'return', session_id=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "USDNZD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb655059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDNZD_br = create_model(\"br\")\n",
    "\n",
    "# Tune the model\n",
    "USDNZD_tuned_br = tune_model(USDNZD_br)\n",
    "\n",
    "# Finalise the model\n",
    "USDNZD_model = finalize_model(USDNZD_tuned_br)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDNZD_model, 'USDNZD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDSGD\n",
    "# Below code creates the regresion model, most of it is adapted from the pycaret tutorial\n",
    "\n",
    "        \n",
    "# Set up the regression\n",
    "USDSGD_reg = setup(data = prepared['USDSGD'], target = 'return', session_id=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "USDSGD_best = compare_models(exclude = ['ransac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d353256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "USDSGD_en = create_model(\"en\")\n",
    "\n",
    "# Tune the model\n",
    "USDSGD_tuned_en = tune_model(USDSGD_en)\n",
    "\n",
    "# Finalise the model\n",
    "USDSGD_model = finalize_model(USDSGD_tuned_en)\n",
    "\n",
    "# Save the model\n",
    "save_model(USDSGD_model, 'USDSGD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a69137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the models ready to be used in the main function\n",
    "loaded_models = {}\n",
    "loaded_models[\"EURUSD\"] = load_model('EURUSD_model')\n",
    "loaded_models[\"GBPUSD\"] = load_model('GBPUSD_model')\n",
    "loaded_models[\"USDCHF\"] = load_model('USDCHF_model')\n",
    "loaded_models[\"USDCAD\"] = load_model('USDCAD_model')\n",
    "loaded_models[\"USDHKD\"] = load_model('USDHKD_model')\n",
    "loaded_models[\"USDAUD\"] = load_model('USDAUD_model')\n",
    "loaded_models[\"USDNZD\"] = load_model('USDNZD_model')\n",
    "loaded_models[\"USDSGD\"] = load_model('USDSGD_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0ce65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the Mongodb database\n",
    "\n",
    "conn_string = \"mongodb://marcus:3wzMJMuAmyC1SklI@ac-7vsa95n-shard-00-00.ylax8sy.mongodb.net:27017,ac-7vsa95n-shard-00-01.ylax8sy.mongodb.net:27017,ac-7vsa95n-shard-00-02.ylax8sy.mongodb.net:27017/?ssl=true&replicaSet=atlas-10zgao-shard-0&authSource=admin&retryWrites=true&w=majority\"\n",
    "try: \n",
    "    dbclient = pymongo.MongoClient(conn_string)\n",
    "except Exception:\n",
    "    print(\"Error:\" + Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273a4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block contains the Mongo db config\n",
    "\n",
    "# Create the db on mondgo db\n",
    "final_pres_db = dbclient['final_pres_live']\n",
    "\n",
    "# Create a dictionaries to store the collections\n",
    "raw = {}\n",
    "ts = {}\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "\n",
    "# Function to drop the raw collection every 6 mins\n",
    "def reset_raw_collection(currency_pairs):\n",
    "    for curr in currency_pairs:\n",
    "        raw[f'{curr[0]}{curr[1]}_raw'].drop()\n",
    "        raw[f'{curr[0]}{curr[1]}_raw'] = final_pres_db[f'{curr[0]}{curr[1]}_raw']\n",
    "\n",
    "\n",
    "# Create the various collections that we need\n",
    "def initialise_collections(currency_pairs):\n",
    "    for curr in currency_pairs:\n",
    "        # for each currency pair create a raw collection (similar to tables in sql)\n",
    "        raw[f'{curr[0]}{curr[1]}_raw'] = final_pres_db[f'{curr[0]}{curr[1]}_raw']\n",
    "        \n",
    "        # for each currency pair create a ts collection (similar to tables in sql)\n",
    "        ts[f'{curr[0]}{curr[1]}_ts'] = final_pres_db[f'{curr[0]}{curr[1]}_ts']\n",
    "        \n",
    "        # for each currency pair create a results collection (similar to tables in sql)\n",
    "        results[f'{curr[0]}{curr[1]}_results'] = final_pres_db[f'{curr[0]}{curr[1]}_results']\n",
    "        \n",
    "        # for each currency pair create a predictions collection (similar to tables in sql)\n",
    "        predictions[f'{curr[0]}{curr[1]}_predictions'] = final_pres_db[f'{curr[0]}{curr[1]}_predicitons']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a86e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below are helper functions for the main function.\n",
    "# This function is slightly modified from polygon sample code to format the date string \n",
    "def ts_to_datetime(ts) -> str:\n",
    "    return datetime.datetime.fromtimestamp(ts / 1000.0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "#----Trading Helper Functions-----\n",
    "\n",
    "# This funtion initialises trading by assigning 5 currencies long positions and 5 currencies short positions.\n",
    "# It adds 100 to their balance.\n",
    "\n",
    "def initialise_trading(currency_pairs, dic):\n",
    "    i = 0\n",
    "    for currency in currency_pairs:\n",
    "        # Set the input variables to the API\n",
    "        from_ = currency[0]\n",
    "        to = currency[1]\n",
    "        i +=1\n",
    "        \n",
    "        if (i % 2 != 0):\n",
    "            dic[f'{from_}{to} position'] = 'long'\n",
    "            dic[f'{from_}{to} balance'] = 100\n",
    "            dic[f'{from_}{to} trade_status'] = 'live'\n",
    "            \n",
    "        \n",
    "        if (i % 2 == 0):\n",
    "            dic[f'{from_}{to} position'] = 'short'\n",
    "            dic[f'{from_}{to} balance'] = 100\n",
    "            dic[f'{from_}{to} trade_status'] = 'live'\n",
    "            \n",
    "\n",
    "# This is a helper function to aide with the stop_loss_strategy below, it follows the four possible scenarios outlined in class\n",
    "def prediction_analysis(actual, prediction, error, trade_position):\n",
    "    \n",
    "    decision = ''\n",
    "    # If the estimate says price is going to go up and the error is favourable \n",
    "    if (prediction > actual) & (error >=0):\n",
    "        if trade_position == 'long':\n",
    "            decision = 'buy'\n",
    "        if trade_position == 'short':\n",
    "            decision = 'exit'\n",
    "    # If the estimate says price is going to go up and the error is not favourable \n",
    "    if (prediction > actual) & (error < 0):\n",
    "        decision = 'do nothing'\n",
    "    # If the estimate says price is going to go down and the error is favourable \n",
    "    if (prediction < actual) & (error >= 0):\n",
    "        decision ='do nothing'\n",
    "    # If the estimate says price is going to go up and the error is not favourable \n",
    "    if (prediction < actual) & (error < 0):\n",
    "        if trade_position == 'long':\n",
    "            decision = 'exit'\n",
    "        if trade_position == 'short':\n",
    "            decision = 'buy'\n",
    "    \n",
    "    return decision\n",
    "\n",
    "\n",
    "# This function contains the stop loss strategy as outlined in the assignments \n",
    "def stop_loss_strategy(currency_pairs, dic, hours_past):\n",
    "    \n",
    "    # This function gets called every hour in the main function\n",
    "\n",
    "    # Loop through each currency pair\n",
    "    for currency in currency_pairs:\n",
    "        # Set the input variables to the API\n",
    "        from_ = currency[0]\n",
    "        to = currency[1]\n",
    "        \n",
    "        \n",
    "        # Sum the 6 minute predictions to give the hourly prediction\n",
    "        \n",
    "        dic[f'{from_}{to} predicted'] = sum(dic[f'{from_}{to} predictions'])\n",
    "        \n",
    "        # Reset the 6 minute predictions for the next hour\n",
    "        \n",
    "        dic[f'{from_}{to} predictions'] = []\n",
    "        \n",
    "        # Calculate the error as a decinal, if the error is positive it was favourable\n",
    "        # (ie the return out performed the prediction), if the error is negative it was not\n",
    "        # favourable (ie the return did worse than the prediction)\n",
    "                    \n",
    "        dic[f'{from_}{to} error'] = (dic[f'{from_}{to} return'] - dic[f'{from_}{to} predicted']) / dic[f'{from_}{to} return']\n",
    "\n",
    "        # Run the `prediction_analysis` helper function to return a decision of buy, do nothing, error\n",
    "        decision = prediction_analysis(dic[f'{from_}{to} return'], dic[f'{from_}{to} predicted'], dic[f'{from_}{to} error'], dic[f'{from_}{to} position'])\n",
    "        \n",
    "        # We can reference the acceptable loss from this logic array. This refactoring saved many lines of copy and pasted code.\n",
    "        # Each element is an acceptable loss, it's index + 1 is its corresponding phase. I.e 0.250 is acceptable in the first hour, 0.100 is acceptable in the second hour.\n",
    "    \n",
    "        logic = [0.250, 0.150, 0.100, 0.050, 0.050, 0.050, 0.050, 0.050, 0.050, 0.050]\n",
    "            \n",
    "               \n",
    "        # If 10 hours have past, exit the trades and compute the profit/loss\n",
    "        if hours_past == 10:\n",
    "            # Exit trades and compute balance, profit or loss\n",
    "            dic[f'{from_}{to} trade_status'] = 'exited'\n",
    "            dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] * (1 - dic[f'{from_}{to} return'])\n",
    "            \n",
    "            if (dic[f'{from_}{to} position'] == 'long'):\n",
    "                dic[f'{from_}{to} profit_loss'] = (dic[f'{from_}{to} balance'] - dic[f'{from_}{to} total_invested'])\n",
    "            \n",
    "            if (dic[f'{from_}{to} position'] == 'short'):\n",
    "                dic[f'{from_}{to} profit_loss'] = -(dic[f'{from_}{to} balance'] - dic[f'{from_}{to} total_invested'])\n",
    "                \n",
    "            \n",
    "                \n",
    "        else:\n",
    "            # Follow the trading logic   \n",
    "            for index, val in enumerate(logic):\n",
    "                # Run the below code in the relevant time period\n",
    "                if hours_past == index+1:\n",
    "                    \n",
    "                    \n",
    "                    # If long\n",
    "                    if (dic[f'{from_}{to} position'] == 'long') & (dic[f'{from_}{to} trade_status'] == 'live'):\n",
    "                    \n",
    "                        # ...and loss is larger than accepted, compute loss and close trade\n",
    "                        if ((dic[f'{from_}{to} return']) < -(logic[index]/100)):\n",
    "                            dic[f'{from_}{to} trade_status'] = 'exited'\n",
    "                            dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] * (1 - dic[f'{from_}{to} return'])\n",
    "                            \n",
    "\n",
    "                        # ...and loss is less than accepted loss, depending on the `prediction_analysis` function we will either buy, do nothing or exit\n",
    "                        \n",
    "                        if ((dic[f'{from_}{to} return']) >= -(logic[index]/100)):\n",
    "                            # If buy compute profit or loss, add it to the position and add another 100 to the trade \n",
    "                            if decision == 'buy':\n",
    "                                dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] + (dic[f'{from_}{to} balance'] * dic[f'{from_}{to} return']) + 100\n",
    "                                dic[f'{from_}{to} total_invested'] += 100\n",
    "                                \n",
    "                            # If do nothing, leave trade running but don't reinvest. Compute the change in balance from the previous hour\n",
    "                            if decision == 'do nothing':\n",
    "                                dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] + (dic[f'{from_}{to} balance'] * dic[f'{from_}{to} return'])\n",
    "\n",
    "                                \n",
    "                            # If exit:\n",
    "                            if decision == 'exit':\n",
    "                                dic[f'{from_}{to} trade_status'] = 'exited'\n",
    "                                dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] * (1 - dic[f'{from_}{to} return'])\n",
    "                        \n",
    "                        dic[f'{from_}{to} profit_loss'] = (dic[f'{from_}{to} balance'] - dic[f'{from_}{to} total_invested'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    # If short   \n",
    "                    if (dic[f'{from_}{to} position'] == 'short') & (dic[f'{from_}{to} trade_status'] == 'live'):\n",
    "                         # ...and gain is larger than accepted, compute loss and close trade\n",
    "                        if ((dic[f'{from_}{to} return']) > (logic[index]/100)):\n",
    "                            dic[f'{from_}{to} trade_status'] = 'exited'\n",
    "                            dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] * (1 - dic[f'{from_}{to} return'])\n",
    "                            \n",
    "                         # If short and gain is less than accepted, depending on the `prediction_analysis` function we will either buy, do nothing or exit\n",
    "                        if ((dic[f'{from_}{to} return']) <= (logic[index]/100)):\n",
    "                            \n",
    "                            # If buy compute profit or loss, add it to the position and add another 100 to the trade\n",
    "                            if decision == 'buy':\n",
    "                                dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] + (dic[f'{from_}{to} balance'] * dic[f'{from_}{to} return']) + 100\n",
    "                                dic[f'{from_}{to} total_invested'] += 100\n",
    "                            \n",
    "                            # # If do nothing, leave trade running but don't reinvest. Compute the change in balance from the previous hour\n",
    "                            if decision == 'do nothing':\n",
    "                                dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] + (dic[f'{from_}{to} balance'] * dic[f'{from_}{to} return'])\n",
    "\n",
    "                            \n",
    "                            if decision == 'exit':\n",
    "                                dic[f'{from_}{to} trade_status'] = 'exited'\n",
    "                                dic[f'{from_}{to} balance'] = dic[f'{from_}{to} balance'] * (1 - dic[f'{from_}{to} return'])\n",
    "                                                            \n",
    "\n",
    "                        dic[f'{from_}{to} profit_loss'] = -(dic[f'{from_}{to} balance'] - dic[f'{from_}{to} total_invested'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Get the current time and format it\n",
    "        insert_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        \n",
    "        # Write the prediction info into the db\n",
    "\n",
    "        res = predictions[f'{from_}{to}_predictions'].insert_one({\n",
    "            \"inserttime\": insert_time,\n",
    "            \"predictedreturn\": dic[f'{from_}{to} predicted'],\n",
    "            \"actualreturn\": dic[f'{from_}{to} return'],\n",
    "            \"error\": dic[f'{from_}{to} error']\n",
    "        })\n",
    "        \n",
    "        # Write the results into the db\n",
    "        \n",
    "        \n",
    "        res = results[f'{from_}{to}_results'].insert_one({\n",
    "            \"inserttime\": insert_time,\n",
    "            \"period\": hours_past,\n",
    "            \"position\": dic[f'{from_}{to} position'],\n",
    "            \"balance\": dic[f'{from_}{to} balance'],\n",
    "            \"profitloss\": dic[f'{from_}{to} profit_loss'],\n",
    "            \"status\": dic[f'{from_}{to} trade_status']\n",
    "        })\n",
    "              \n",
    "\n",
    "# --- Main function ----        \n",
    "# This main function repeatedly calls the polygon api every 1 seconds for 24 hours \n",
    "# and stores the results.\n",
    "def main(currency_pairs):\n",
    "    # The api key given by the professor\n",
    "    key = \"beBybSi8daPgsTp5yx5cHtHpYcrjp5Jq\"\n",
    "    \n",
    "    # Number of list iterations - each one should last about 1 second\n",
    "    count = 0\n",
    "    agg_count = 0\n",
    "    hour_count = 0\n",
    "    hours_past = 0\n",
    "    \n",
    "    # Create a dictionary of variables that will act as local storage for the various currency paris\n",
    "    dic = {}\n",
    "    \n",
    "    for currency in currency_pairs:\n",
    "        # Set the input variables to the API\n",
    "        from_ = currency[0]\n",
    "        to = currency[1]\n",
    "        \n",
    "        #Initialise the variables that we will need\n",
    "        dic[f'{from_}{to} maximum'] = float('-inf')\n",
    "        dic[f'{from_}{to} minimum'] = float('inf')\n",
    "        dic[f'{from_}{to} prices'] = []\n",
    "        dic[f'{from_}{to} running_total'] = 0\n",
    "        dic[f'{from_}{to} cross_count'] = 0\n",
    "        dic[f'{from_}{to} period'] = 1\n",
    "        dic[f'{from_}{to} keltner_upper_bands'] = []\n",
    "        dic[f'{from_}{to} keltner_lower_bands'] = []\n",
    "        dic[f'{from_}{to} avg_price'] = None\n",
    "        dic[f'{from_}{to} last_price'] = None\n",
    "        dic[f'{from_}{to} upper_count'] = 0\n",
    "        dic[f'{from_}{to} lower_count'] = 0\n",
    "        dic[f'{from_}{to} fd'] = 0\n",
    "        dic[f'{from_}{to} old_mean'] = 0\n",
    "        dic[f'{from_}{to} mean'] = 0\n",
    "        dic[f'{from_}{to} return'] = 0\n",
    "        # variables that will keep track of investments\n",
    "        dic[f'{from_}{to} balance'] = 0       # we will initialise this to 100\n",
    "        dic[f'{from_}{to} profit_loss'] = 0\n",
    "        dic[f'{from_}{to} total_invested'] = 100\n",
    "        dic[f'{from_}{to} number_of_hours'] = 0\n",
    "        dic[f'{from_}{to} trade_status'] = '' # live or exited\n",
    "        dic[f'{from_}{to} position'] = ''     # long or short\n",
    "        dic[f'{from_}{to} predictions'] = []     # Every six minutes the prediction is added to the array\n",
    "        dic[f'{from_}{to} predicted'] = 0     # predicted return from the model\n",
    "        dic[f'{from_}{to} error'] = 0         # error from prediction\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "    # Create the needed collections in the database\n",
    "    initialise_collections(currency_pairs)\n",
    "    \n",
    "    \n",
    "    # Start trading!\n",
    "    initialise_trading(currency_pairs, dic)\n",
    "    \n",
    "    # Open a RESTClient for making the api calls\n",
    "    with RESTClient(key) as client:\n",
    "        # Loop that runs until the total duration of the program hits 24 hours. \n",
    "        while count < 86400: # 86400 seconds = 24 hours\n",
    "            \n",
    "            \n",
    "            # Check to see if 6 minutes has been reached or not\n",
    "            if agg_count == 180:\n",
    "                \n",
    "                # Clear the raw data tables\n",
    "                reset_raw_collection(currency_pairs)\n",
    "                agg_count = 0\n",
    "            \n",
    "            \n",
    "            # Every hour run the trailing stop strategy (3600 seconds)\n",
    "            if hour_count == 1800:\n",
    "\n",
    "                # Run the stop loss strategy\n",
    "                stop_loss_strategy(currency_pairs, dic, hours_past)\n",
    "                \n",
    "                 # Increment hours that have past\n",
    "                hours_past += 1\n",
    "\n",
    "                # Reset hour count\n",
    "                hour_count = 0\n",
    "                \n",
    "            \n",
    "            # After I established the MongoDB conenction, dode was taking 2 seconds to run so I decided to halve the counter times (360 =180, 3600=1800)\n",
    "            # And comment out the sleep time\n",
    "            # time.sleep(0.4)\n",
    "\n",
    "\n",
    "            # Comment this in to check how long the code takes to run\n",
    "            #print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            \n",
    "            # Increment the counters\n",
    "            count += 1\n",
    "            agg_count += 1\n",
    "            hour_count += 1\n",
    "            \n",
    "            \n",
    "            # Loop through each currency pair\n",
    "            for currency in currency_pairs:\n",
    "                # Set the input variables to the API\n",
    "                from_ = currency[0]\n",
    "                to = currency[1]\n",
    "                \n",
    "                if agg_count == 180:\n",
    "            \n",
    "                    # Every six minutes...\n",
    "                    \n",
    "                    # Calculate the mean\n",
    "                    prices_arr = np.array(dic[f'{from_}{to} prices'])\n",
    "                    dic[f'{from_}{to} running_total'] = prices_arr.sum()\n",
    "                    dic[f'{from_}{to} mean'] = dic[f'{from_}{to} running_total'] / len(prices_arr)\n",
    "                    \n",
    "                    # Calculate the return\n",
    "                    if  dic[f'{from_}{to} period'] > 1:\n",
    "                        dic[f'{from_}{to} return'] = (dic[f'{from_}{to} mean'] - dic[f'{from_}{to} old_mean']) / dic[f'{from_}{to} old_mean']\n",
    "                    else:\n",
    "                        dic[f'{from_}{to} return'] = 0\n",
    "                        \n",
    "                        \n",
    "                    # Assign the previous mean to the old_mean\n",
    "                    dic[f'{from_}{to} old_mean'] = dic[f'{from_}{to} mean']\n",
    "\n",
    "                    \n",
    "                    # Reset values\n",
    "                    dic[f'{from_}{to} prices'] = []\n",
    "                    dic[f'{from_}{to} running_total'] = 0\n",
    "    \n",
    "        \n",
    "                    # Write the volatility info to database\n",
    "            \n",
    "\n",
    "                    res = ts[f'{from_}{to}_ts'].insert_one({\n",
    "                       \"inserttime\": insert_time,\n",
    "                        \"period\": dic[f'{from_}{to} period'],\n",
    "                        \"maximum\": dic[f'{from_}{to} maximum'],\n",
    "                        \"minimum\": dic[f'{from_}{to} minimum'],\n",
    "                        \"mean\": dic[f'{from_}{to} mean'],\n",
    "                        \"volatility\": dic[f'{from_}{to} vol'],\n",
    "                        \"fd\": dic[f'{from_}{to} fd'],\n",
    "                        \"return\": dic[f'{from_}{to} return']\n",
    "                    })\n",
    "                   \n",
    "                    \n",
    "                    # Run the prediction for next 6 minute period\n",
    "                    \n",
    "                    data = {\n",
    "                        'inserttime': [insert_time],\n",
    "                        'maximum': [dic[f'{from_}{to} maximum']],\n",
    "                        'minimum': [dic[f'{from_}{to} minimum']],\n",
    "                        'mean': [dic[f'{from_}{to} mean']],\n",
    "                        'volatility': [dic[f'{from_}{to} vol']],\n",
    "                        'fd': [dic[f'{from_}{to} fd']],\n",
    "                        'return': [dic[f'{from_}{to} return']],\n",
    "                        'fiveyear': 3.654,\n",
    "                        'tenyear': 3.45, \n",
    "                        'thirtyyear': 3.415\n",
    "                    }\n",
    "                    df = pd.DataFrame(data=data)\n",
    "                    predictions[f'{from_}{to}'] = predict_model(loaded_models[f'{from_}{to}'], data = df)\n",
    "\n",
    "                    # Save the prediction to the dictionary                    \n",
    "                    dic[f'{from_}{to} predictions'].append(predictions[f'{from_}{to}'].loc[0]['Label'] / 100000)\n",
    "                    \n",
    "                    \n",
    "                    # Reset the currency specific variables\n",
    "                    dic[f'{from_}{to} maximum'] = float('-inf')\n",
    "                    dic[f'{from_}{to} minimum'] = float('inf')\n",
    "                    dic[f'{from_}{to} cross_count'] = 0 \n",
    "                    dic[f'{from_}{to} period'] +=1\n",
    "\n",
    "                    dic[f'{from_}{to} keltner_upper_bands'] = []\n",
    "                    dic[f'{from_}{to} keltner_lower_bands'] = []\n",
    "                    dic[f'{from_}{to} upper_count'] = 0\n",
    "                    dic[f'{from_}{to} lower_count'] = 0\n",
    "\n",
    "\n",
    "                    # If the first period has passed, calculate the keltner bands\n",
    "                    if dic[f'{from_}{to} period'] > 1:\n",
    "\n",
    "                    # Create 100 upper Keltner bands\n",
    "                        for num in range(100):\n",
    "                            calc = dic[f'{from_}{to} mean'] + num*0.025*dic[f'{from_}{to} vol']\n",
    "                            dic[f'{from_}{to} keltner_upper_bands'].append(calc)\n",
    "                            \n",
    "                    # Create 100 lower Keltner bands\n",
    "                        for num in range(100):\n",
    "                            calc = dic[f'{from_}{to} mean'] - num*0.025*dic[f'{from_}{to} vol']\n",
    "                            dic[f'{from_}{to} keltner_lower_bands'].append(calc)\n",
    "                        \n",
    "                \n",
    "\n",
    "                # Call the API with the required parameters\n",
    "                try:\n",
    "                    resp = client.forex_currencies_real_time_currency_conversion(from_, to, amount=100, precision=2)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # This gets the Last Trade object defined in the API Resource\n",
    "                last_trade = resp.last\n",
    "\n",
    "                # Format the timestamp from the result\n",
    "                dt = ts_to_datetime(last_trade[\"timestamp\"])\n",
    "\n",
    "                # Get the current time and format it\n",
    "                insert_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                \n",
    "                # Assign the old average price to the last price\n",
    "                dic[f'{from_}{to} last_price'] = dic[f'{from_}{to} avg_price']\n",
    "                \n",
    "                # Calculate the new average price by taking the average of the bid and ask prices\n",
    "                avg_price = (last_trade['bid'] + last_trade['ask'])/2\n",
    "                dic[f'{from_}{to} avg_price'] = (last_trade['bid'] + last_trade['ask'])/2\n",
    "                \n",
    "                # Calculate the max price in the past six minutes\n",
    "                if dic[f'{from_}{to} avg_price'] > dic[f'{from_}{to} maximum']:\n",
    "                    dic[f'{from_}{to} maximum'] = dic[f'{from_}{to} avg_price']\n",
    "                            \n",
    "                # Calculate the min price in the last six minutes\n",
    "                if dic[f'{from_}{to} avg_price'] < dic[f'{from_}{to} minimum']:\n",
    "                    dic[f'{from_}{to} minimum'] = dic[f'{from_}{to} avg_price']\n",
    "                \n",
    "                # Calculate the volatility over the last six minutes, ensure that we divide by the average price in order to standardise the value\n",
    "                dic[f'{from_}{to} vol'] = (dic[f'{from_}{to} maximum'] - dic[f'{from_}{to} minimum']) / dic[f'{from_}{to} avg_price']\n",
    "                \n",
    "                # Replace the vol with a class (1,2,3)\n",
    "                \n",
    "                vol_arr = vol_data[f'{from_}{to}'].to_numpy().tolist()\n",
    "                vol_arr.append(dic[f'{from_}{to} vol'])\n",
    "                vol_arr.sort()\n",
    "                vol_r = vol_arr.index(dic[f'{from_}{to} vol'])\n",
    "                if vol_r <= 120:\n",
    "                    dic[f'{from_}{to} vol'] = 1\n",
    "                    \n",
    "                if (vol_r > 120) &  vol_r <= 240:\n",
    "                    dic[f'{from_}{to} vol'] = 2\n",
    "                \n",
    "                if (vol_r > 240):\n",
    "                    dic[f'{from_}{to} vol'] = 3\n",
    "                    \n",
    "                \n",
    "                # Calculate the fractal dimension\n",
    "                # For each new price we want to know how many bands have been crossed. \n",
    "        \n",
    "                upper = np.array(dic[f'{from_}{to} keltner_upper_bands'])\n",
    "                lower = np.array(dic[f'{from_}{to} keltner_lower_bands'])\n",
    "                \n",
    "                # How many numbers in the keltner band are greater than the old price and less than the new price\n",
    "                if dic[f'{from_}{to} last_price'] is not None:\n",
    "                    dic[f'{from_}{to} upper_count'] = ((dic[f'{from_}{to} last_price'] < upper) & (upper < dic[f'{from_}{to} avg_price'])).sum()\n",
    "\n",
    "                # How many numbers in the keltner band are less than the old price and greater than the new price\n",
    "                if dic[f'{from_}{to} last_price'] is not None:\n",
    "                    dic[f'{from_}{to} lower_count'] = ((dic[f'{from_}{to} last_price'] > lower) & (lower > dic[f'{from_}{to} avg_price'])).sum()\n",
    "\n",
    "                # Add the above counts from upper and lower bands together\n",
    "                dic[f'{from_}{to} cross'] = dic[f'{from_}{to} upper_count'] + dic[f'{from_}{to} lower_count']\n",
    "                \n",
    "                # Add the total to the running total of crosses over the six minute period\n",
    "                dic[f'{from_}{to} cross_count'] = dic[f'{from_}{to} cross_count'] +  dic[f'{from_}{to} cross']\n",
    "                \n",
    "                # Divide the cross_count by the volatility in order to calculte the fractal dimenstion\n",
    "                if  (dic[f'{from_}{to} maximum'] - dic[f'{from_}{to} minimum']) != 0:\n",
    "                     dic[f'{from_}{to} fd'] = dic[f'{from_}{to} cross_count'] /  (dic[f'{from_}{to} maximum'] - dic[f'{from_}{to} minimum'])\n",
    "                \n",
    "                # Replace the fd with a class (1,2,3)\n",
    "                fd_arr = fd_data[f'{from_}{to}'].to_numpy().tolist()\n",
    "                fd_arr.append(dic[f'{from_}{to} fd'])\n",
    "                fd_arr.sort()\n",
    "                fd_r = fd_arr.index(dic[f'{from_}{to} fd'])\n",
    "                if fd_r <= 120:\n",
    "                    dic[f'{from_}{to} fd'] = 1\n",
    "                    \n",
    "                if (fd_r > 120) &  fd_r <= 240:\n",
    "                    dic[f'{from_}{to} fd'] = 2\n",
    "                \n",
    "                if (fd_r > 360):\n",
    "                    dic[f'{from_}{to} fd'] = 3\n",
    "                \n",
    "                # Keep track of prices over last 6 minutes\n",
    "                (dic[f'{from_}{to} prices']).append(dic[f'{from_}{to} avg_price'])\n",
    "                \n",
    "                \n",
    "                # Write the raw data to Mongodb\n",
    "                \n",
    "                res = raw[f'{from_}{to}_raw'].insert_one({\n",
    "                    \"ticktime\": dt,\n",
    "                    \"fxrate\": avg_price,\n",
    "                    \"inserttime\": insert_time\n",
    "                })\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0814384",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/var/folders/56/58bs7fss6hbc3wf9589_7mww0000gn/T/ipykernel_68352/786041253.py\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<cell line: 2>\u001b[0m\n    main(currency_pairs)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/56/58bs7fss6hbc3wf9589_7mww0000gn/T/ipykernel_68352/2073176721.py\"\u001b[0;36m, line \u001b[0;32m260\u001b[0;36m, in \u001b[0;35mmain\u001b[0;36m\u001b[0m\n\u001b[0;31m    initialise_trading(engine, currency_pairs, dic)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m\u001b[0;31m:\u001b[0m name 'engine' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Run the main data collection loop\n",
    "main(currency_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7037a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
